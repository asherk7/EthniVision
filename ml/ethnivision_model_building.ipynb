{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ethnicities, Age, and Gender with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "1. *Introduction*\n",
    "2. *Data Preperation*\n",
    "    * 2.1 Data Cleaning/Preparation\n",
    "    * 2.2 Data Loading\n",
    "    * 2.3 Data Exploration\n",
    "    * 2.4 Data Preprocessing\n",
    "3. *Model Architecture*\n",
    "    * 3.1 Neural Network Design\n",
    "    * 3.2 Model Compilation\n",
    "4. *Model Training*\n",
    "    * 4.1 Training Process\n",
    "    * 4.2 Improving the Model\n",
    "5. *Model Evaluation*\n",
    "    * 5.1 Model Performance\n",
    "    * 5.2 Confusion Matrix\n",
    "    * 5.3 Model Prediction Graphing\n",
    "6. *Model Deployment*\n",
    "    * 6.1 Model Saving\n",
    "7. *Conclusion*\n",
    "8. *References*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction:\n",
    "In this notebook, we will explore the process of building a neural network model to predict ethnicities, age, and gender based on certain features. Predicting ethnicities, age, and gender can have various applications, including demographic analysis, social studies, and more. We will follow a step-by-step approach, covering data preprocessing, model architecture design, training, evaluation, and interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Cleaning/Preparation\n",
    "\n",
    "The dataset from FairFace is split between a training set and a validation set, lacking the test set. In this section, I will:\n",
    "- Combine all the images into one folder\n",
    "- Rename the images starting from 1 to the total number of images\n",
    "- Compile all the csv files into one with the new names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the training images to the all images folder\n",
    "temp_train_path = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp\\\\train\"\n",
    "all_images = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp\\\\all\"\n",
    "\n",
    "train_files = os.listdir(temp_train_path)\n",
    "\n",
    "# Moving the training images to the all images folder\n",
    "for file_name in train_files:\n",
    "    train_path = os.path.join(temp_train_path, file_name)\n",
    "    all_path = os.path.join(all_images, file_name)\n",
    "    shutil.move(train_path, all_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the contents of the train csv to a general csv file\n",
    "# Changing the file column to only include the name of the file\n",
    "temp_train_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp_csv\\\\images_train.csv\"\n",
    "general_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp_csv\\\\all.csv\"\n",
    "\n",
    "# getting the data from the csv without the extra path on the filename\n",
    "new_rows = []\n",
    "with open(temp_train_csv, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        modified_row = [row[0].split('/')[-1]] + row[1:]\n",
    "        new_rows.append(modified_row)\n",
    "\n",
    "# writing the data back into the csv\n",
    "with open(general_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86745"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting a variable for the name of the last image in train\n",
    "img_num = len(os.listdir(all_images)) + 1\n",
    "img_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the validation images and csv also start from 1, we will have to rename the images starting from the end of the training images, while also renaming the file column in the val csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the validation images\n",
    "temp_val_path = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp\\\\val\"\n",
    "all_images = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp\\\\all\"\n",
    "temp_val_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp_csv\\\\images_val.csv\"\n",
    "\n",
    "# getting our images without the extra path\n",
    "image_data = []\n",
    "with open(temp_val_csv, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        modified_row = [row[0].split('/')[-1]] + row[1:]\n",
    "        image_data.append(modified_row)\n",
    "\n",
    "# get rid of the header row\n",
    "image_data = image_data[1:]\n",
    "\n",
    "# changing the name of the images and the csv data and moving them\n",
    "for index, image in enumerate(image_data, start=img_num):\n",
    "    new_image_name = str(index) + \".jpg\"\n",
    "    new_image_path = os.path.join(all_images, new_image_name)\n",
    "    old_image_path = os.path.join(temp_val_path, image[0])\n",
    "    shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    for i, row in enumerate(image_data):\n",
    "        if (row[0] == image[0]):\n",
    "            image_data[i][0] = new_image_name\n",
    "            break\n",
    "\n",
    "# writing the new data into the csv file\n",
    "with open(temp_val_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the val csv with the general csv\n",
    "general_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp_csv\\\\all.csv\"\n",
    "temp_val_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\temp_csv\\\\images_val.csv\"\n",
    "\n",
    "# getting the data from general csv\n",
    "rows = []\n",
    "with open(general_csv, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "\n",
    "# adding the val data to the data we already have\n",
    "with open(temp_val_csv, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "\n",
    "# writing the data to the general csv\n",
    "with open(general_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Loading\n",
    "\n",
    "Now that we've cleaned our data, we can start loading it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\all.csv\"\n",
    "df = pd.read_csv(general_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph distribution of ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph genders of each ethnicity compared to age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph distribution of gender and race to amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing example images\n",
    "import random\n",
    "image_source = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\all\"\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i+1)\n",
    "    rand = random.randint(0, len(image_source))\n",
    "    img = df.iloc[rand, 0]\n",
    "    image_path = os.path.join(image_source, img)\n",
    "    plt.imshow(cv2.imread(image_source))\n",
    "    plt.title(f\"age: {df.iloc[rand, 1]}, gender: {df.iloc[rand, 2]}, ethnicity: {df.iloc[rand, 3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to split the images and csv into a 70-15-15 split for training, validation, and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\all\"\n",
    "csv_source = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\all.csv\"\n",
    "image_destination = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\images\"\n",
    "csv_destination = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\csv\"\n",
    "\n",
    "# creating the directories\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "for split in splits:\n",
    "    os.mkdir(os.path.join(image_destination, split))\n",
    "\n",
    "# getting the data from the csv file\n",
    "csv_data = []\n",
    "header = []\n",
    "with open(csv_source, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    header = reader.__next__() # getting the header and skipping it\n",
    "    for row in reader:\n",
    "        csv_data.append(row)\n",
    "\n",
    "random.shuffle(csv_data)\n",
    "\n",
    "# splitting the data into train, val, test\n",
    "total_images = len(csv_data)\n",
    "train_size = int(0.70*total_images)\n",
    "val_size = int(0.15*total_images)\n",
    "\n",
    "train_data = csv_data[ : train_size]\n",
    "val_data = csv_data[train_size : train_size + val_size]\n",
    "test_data = csv_data[train_size + val_size : ]\n",
    "\n",
    "# moving the images and creating the csv files\n",
    "for split, data in zip(splits, [train_data, val_data, test_data]):\n",
    "    for row in data:\n",
    "        image_path = os.path.join(image_source, row[0])\n",
    "        split_destination = os.path.join(image_destination, split)\n",
    "        shutil.move(image_path, split_destination)\n",
    "\n",
    "    csv_path = os.path.join(csv_destination, split + \".csv\")\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        for row in data:\n",
    "            modified_row = [os.path.join(split, row[0])] + row[1:]\n",
    "            writer.writerow(modified_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68388 14654 14656\n",
      "97698\n",
      "68388\n",
      "14654\n",
      "14656\n",
      "97698\n"
     ]
    }
   ],
   "source": [
    "# making sure the data was moved properly\n",
    "train_dir = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\images\\\\train\"\n",
    "val_dir = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\images\\\\val\"\n",
    "test_dir = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\images\\\\test\"\n",
    "train_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\csv\\\\train.csv\"\n",
    "val_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\csv\\\\val.csv\"\n",
    "test_csv = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\csv\\\\test.csv\"\n",
    "\n",
    "train_len = len(os.listdir(train_dir))\n",
    "val_len = len(os.listdir(val_dir))\n",
    "test_len = len(os.listdir(test_dir))\n",
    "\n",
    "print(train_len, val_len, test_len)\n",
    "print(train_len + val_len + test_len)\n",
    "\n",
    "counter = 0\n",
    "with open(train_csv, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        counter += 1\n",
    "print(counter)\n",
    "\n",
    "counter1 = 0\n",
    "with open(val_csv, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        counter1 += 1\n",
    "print(counter1)\n",
    "\n",
    "counter2 = 0\n",
    "with open(test_csv, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        counter2 += 1\n",
    "print(counter2)\n",
    "\n",
    "print(counter + counter1 + counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "val_df = pd.read_csv(val_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train\\34113.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train\\58446.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train\\27338.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train\\60223.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train\\94498.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file    age  gender             race  service_test\n",
       "0  train\\34113.jpg  10-19  Female  Latino_Hispanic          True\n",
       "1  train\\58446.jpg    3-9    Male  Latino_Hispanic         False\n",
       "2  train\\27338.jpg  30-39  Female       East Asian          True\n",
       "3  train\\60223.jpg  50-59  Female  Latino_Hispanic          True\n",
       "4  train\\94498.jpg  30-39    Male  Latino_Hispanic         False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val\\72512.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val\\60392.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val\\65764.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val\\15221.jpg</td>\n",
       "      <td>40-49</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val\\12071.jpg</td>\n",
       "      <td>10-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            file    age  gender        race  service_test\n",
       "0  val\\72512.jpg  20-29  Female       White         False\n",
       "1  val\\60392.jpg  50-59    Male  East Asian         False\n",
       "2  val\\65764.jpg  30-39    Male       Black          True\n",
       "3  val\\15221.jpg  40-49  Female       White         False\n",
       "4  val\\12071.jpg  10-19  Female       White          True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test\\53352.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test\\95368.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test\\331.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test\\18069.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test\\25704.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file    age  gender             race  service_test\n",
       "0  test\\53352.jpg    3-9  Female  Latino_Hispanic          True\n",
       "1  test\\95368.jpg  20-29  Female  Southeast Asian          True\n",
       "2    test\\331.jpg  20-29  Female            White         False\n",
       "3  test\\18069.jpg  30-39  Female  Latino_Hispanic         False\n",
       "4  test\\25704.jpg  50-59    Male            White         False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the dlib library to detect and crop the faces, and store these cropped faces for training, validation, and testing later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_dlib_pybind11.cnn_face_detection_model_v1 at 0x2183d8fb7b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_detector = dlib.cnn_face_detection_model_v1('dlib_models/mmod_human_face_detector.dat')\n",
    "face_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to detect a face, crop the face, and save the face to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face_and_save(image_name, image_path, output_folder):\n",
    "    # Load the image, convert to grayscale, and detect\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize the image to speed up detection\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    aspect_ratio = original_width / original_height\n",
    "    target_width = 128\n",
    "    target_height = int(target_width / aspect_ratio)\n",
    "    resized_image = cv2.resize(gray, (target_width, target_height))\n",
    "\n",
    "    faces = face_detector(resized_image, 1)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        print(\"No faces found in the image\")\n",
    "        return\n",
    "\n",
    "    # Process the first detected face, since we only have data for the main face in each image\n",
    "    for idx, face in enumerate(faces):\n",
    "        # Get the coordinates of the face rectangle\n",
    "        x, y, w, h = face.rect.left(), face.rect.top(), face.rect.width(), face.rect.height()\n",
    "        \n",
    "        # Calculate the corresponding coordinates on the original image\n",
    "        x = int(x * (original_width / target_width))\n",
    "        y = int(y * (original_height / target_height))\n",
    "        w = int(w * (original_width / target_width))\n",
    "        h = int(h * (original_height / target_height))\n",
    "        face_img = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Save the cropped face\n",
    "        output_path = os.path.join(output_folder, image_name)\n",
    "        cv2.imwrite(output_path, face_img)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\images\"\n",
    "image_destination = \"C:\\\\Users\\\\mashe\\\\Downloads\\\\cropped_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through the training, validation and test images using the csv's to crop the images and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = train_df[\"file\"]\n",
    "val_files = val_df[\"file\"]\n",
    "test_files = test_df[\"file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    image_path = os.path.join(image_source, image)\n",
    "    crop_face_and_save(image, image_path, image_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using parallel processing to compute the images faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n",
      "No faces found in the image\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    executor.map(process_image, train_files)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    executor.map(process_image, val_files)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    executor.map(process_image, test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have detected and cropped most faces, we will find and remove the faces that weren't cropped from our dataframes since they are not useful for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the training csv\n",
    "files = train_df['file']\n",
    "for image in files:\n",
    "    image_path = os.path.join(image_source, image)\n",
    "    if not os.path.exists(image_path):\n",
    "        train_df.drop(train_df[train_df['file'] == image].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the training csv\n",
    "files = val_df['file']\n",
    "for image in files:\n",
    "    image_path = os.path.join(image_source, image)\n",
    "    if not os.path.exists(image_path):\n",
    "        val_df.drop(val_df[val_df['file'] == image].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the training csv\n",
    "files = test_df['file']\n",
    "for image in files:\n",
    "    image_path = os.path.join(image_source, image)\n",
    "    if not os.path.exists(image_path):\n",
    "        test_df.drop(test_df[test_df['file'] == image].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our csv and cropped images, we can begin to prepare our data for training by converting the images in each set into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning the training, validation, and testing sets into tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning our data into numbers\n",
    "def data_transform(df):\n",
    "    # one-hot encode the age categories\n",
    "    # turn gender into 0 or 1\n",
    "    # one hot encode ethnicities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Neural Network Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Improving the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "improving a model:\n",
    "1. Creating a model - we can add more layers, increase the number of neurons within each of the hidden layers, or change the activation functions of each layer\n",
    "2. Compiling a model - we can change the optimization function, or the **learning rate** of the optimization function, or perhaps the **loss** function\n",
    "3. Fitting a model - we can fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)\n",
    "- add layers\n",
    "- increase the number of hidden units\n",
    "- change the activation functions (ReLU, tanh, softmax/sigmoid, etc) (combine linear and non-linear functions)\n",
    "- change the optimization function (SGD, Adam, etc)\n",
    "- change the loss function (MAE, Huber, BinaryCrossentropy, CategoricalCrossentropy, etc)\n",
    "- find the ideal/change the learning rate (most important hyperparameter) (how much the model updates the patterns it learns)\n",
    "- fit on more data (more examples to learn patterns)\n",
    "- train for longer (more epochs)\n",
    "- keep experimenting with each hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluating a model:\n",
    "- visualizing (data, model, predictions, training, etc)\n",
    "- comparing (predictions to ground truth labels)\n",
    "- evaluation metrics (MAE, Crossentropy, Precision/Recall/F1(classification report), confusion matrix, etc)\n",
    "- tweaking/experiment (small experiments, then compare, then tweak, then compare, etc)\n",
    "(plot_model, summary, plotting data/learning rate, history, decision boundary, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using classification evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_preds = tf.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall and f1\n",
    "m = tf.keras.metrics.Precision()\n",
    "m.update_state(y_test, y_preds)\n",
    "print(m.result())\n",
    "n = tf.keras.metrics.Recall()\n",
    "n.update_state(y_test, y_preds)\n",
    "print(n.result())\n",
    "print(f1_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "classification_report(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remix of sci-kit learns plot_confusion_matrix\n",
    "# https://scikit-learn.org/1.0/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "\n",
    "import itertools\n",
    "figsize = (10, 10)\n",
    "\n",
    "# create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_preds)\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] #normalize our confusion matrix\n",
    "n_classes = cm.shape[0] #gets the number of classes\n",
    "\n",
    "# prettify the matrix\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "# create a matrix plot\n",
    "cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# create classes\n",
    "if classes:\n",
    "    labels = classes\n",
    "else:\n",
    "    labels = np.arange(cm.shape[0])\n",
    "\n",
    "# label the axises\n",
    "ax.set(\n",
    "    title=\"Confusion matrix\",\n",
    "    xlabel=\"predicted label\",\n",
    "    ylabel=\"true label\",\n",
    "    xticks=np.arange(n_classes),\n",
    "    yticks=np.arange(n_classes),\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels\n",
    "    )\n",
    "\n",
    "# set threshold for different colours\n",
    "threshold = (cm.max() + cm.min()) / 2\n",
    "\n",
    "# plot the text on each cell\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "    horizontalalignment=\"center\",\n",
    "    color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "    size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Model Prediction Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random image and the prediction/truth\n",
    "import random\n",
    "def plot_random_image(model, images, true_labels, classes):\n",
    "    \"\"\"\n",
    "    Picks a random image, plots it and labels it with prediction and truth label\n",
    "    \"\"\"\n",
    "    # set up random integer\n",
    "    i = random.randint(0, len(images))\n",
    "    # create predictions and targets\n",
    "    target_image = images[i]\n",
    "    pred_probs = model.predict(target_image.reshape(1, 28, 28))\n",
    "    # need to reshape because we predict on array of images\n",
    "    pred_label = classes[pred_probs.argmax()]\n",
    "    true_label = classes[true_labels[i]]\n",
    "    # plot the image\n",
    "    plt.imshow(target_image, cmap=plt.cm.binary)\n",
    "    # change the color of the titles depending on if the prediction is right or wrong\n",
    "    if (pred_label == true_label):\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        color = \"red\"\n",
    "    # add xlabel information(prediction/true label)\n",
    "    plt.xlabel(\"pred: {} {:2.0f}% (True: {})\".format(pred_label,\n",
    "                                                    100*tf.reduce_max(pred_probs),\n",
    "                                                    true_label),\n",
    "                                                    color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_image(model, X_test, y_test, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we successfully developed a machine learning model for ethnicity, age, and gender predictions from facial images. Key highlights include:\n",
    "\n",
    "- Thoughtful data collection and preprocessing contributed to model accuracy.\n",
    "- Convolutional Neural Networks effectively captured facial features.\n",
    "- Rigorous validation and testing ensured reliable performance.\n",
    "- The model was seamlessly integrated into our full-stack website.\n",
    "- Opportunities for ongoing improvement and expansion remain.\n",
    "\n",
    "If you made it this far, thanks for joining me on this journey exploring the power of modern machine learning API's and frameworks. I hope you enjoyed it as much as I did!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was retrieved from the FairFace study.\n",
    "\n",
    "Karkkainen, Kimmo and Joo, Jungseock. (2021). FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age for Bias Measurement and Mitigation. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 1548-1558. 10.1109/WACV48630.2021.00159"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
